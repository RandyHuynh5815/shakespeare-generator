{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make Thy Own Markov Chains"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With all the math thrown at you, you may think that building a Markov chain would be extremely painful. In actuality, it is simpler than you think, and there are MULTIPLE ways to do it. We are going to implement an autocomplete program for Shakespeare's works. Let us walk through the progress of doing so."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Act I: Setting Up The Scene"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This should be a given, but we got to import the packages we may need in order to get this to work. Before running the imports, make sure to set up the environment using the requirements files. To install the neccessary packages, just simply write the command in the terminal.  \n",
    "\n",
    "pip install -r requirements.txt\n",
    "\n",
    "Afterwards, run the following block of code to ensure everything is installed properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from collections import defaultdict\n",
    "import random\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Confirm that you are in the right directory by running the code block below. It should end with 'shakespeare-generator'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\randy\\Productivity\\shakespeare-generator\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's double-check to see if all of our data is there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1henryiv.txt',\n",
       " '1henryvi.txt',\n",
       " '2henryiv.txt',\n",
       " '2henryvi.txt',\n",
       " '3henryvi.txt',\n",
       " 'allswell.txt',\n",
       " 'asyoulikeit.txt',\n",
       " 'cleopatra.txt',\n",
       " 'comedy_errors.txt',\n",
       " 'coriolanus.txt',\n",
       " 'cymbeline.txt',\n",
       " 'hamlet.txt',\n",
       " 'henryv.txt',\n",
       " 'henryviii.txt',\n",
       " 'john.txt',\n",
       " 'julius_caesar.txt',\n",
       " 'lear.txt',\n",
       " 'lll.txt',\n",
       " 'macbeth.txt',\n",
       " 'measure.txt',\n",
       " 'merchant.txt',\n",
       " 'merry_wives.txt',\n",
       " 'midsummer.txt',\n",
       " 'much_ado.txt',\n",
       " 'othello.txt',\n",
       " 'pericles.txt',\n",
       " 'richardii.txt',\n",
       " 'richardiii.txt',\n",
       " 'romeo_juliet.txt',\n",
       " 'taming_shrew.txt',\n",
       " 'tempest.txt',\n",
       " 'timon.txt',\n",
       " 'titus.txt',\n",
       " 'troilus_cressida.txt',\n",
       " 'twelfth_night.txt',\n",
       " 'two_gentlemen.txt',\n",
       " 'winters_tale.txt']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "oh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is no data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's quickly learn how to collect the data we would need in the first place."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aside: Scrape Thy Data From the Hands of Shakespeare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to do this, we will go back to the presentation and then head over to scraper.py to test your knowledge."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we shall check our data's prescence once again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir('data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hurrah! Our data directory is plentiful. Now to begin the Markov chain creation process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Act II: Sentencing Thy Text Into Chains"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code block below sets the stage in order to place the sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_counter = defaultdict(int)\n",
    "sentences = list()\n",
    "\n",
    "n = 10 # Feel free to play around with this value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_TODO_**: _We need a way to extract the sentences from all the text given to us. Let us be bold and do so FROM SCRATCH! But first we need to set some requirements/steps in order for us to be on the same page._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Iterate through every text file in our newly created data folder.\n",
    "2. Open each text file and read all the text at once.\n",
    "3. To normalize the sentences, we replace every whitespace with a space and every ending punctuation with a period. (We will still maintain the commas and semicolons and such for now.)\n",
    "4. Split by period."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Replacing standards**\n",
    "1. ['\\r', '\\n', '-'] -> ' '\n",
    "2. ['?', '!'] -> '.'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hints**\n",
    "1. os.listdir(dir: str) -> List[str] = Retrieves a list of files found within the directory. (Used above)\n",
    "2. s.split(char: str) -> List[str] = Splits s by a char and gives you a list of all segments from the split\n",
    "3. s.replace(old, new) -> str = Replaces every instance of old with new in s\n",
    "4. l1.extends(l2) -> Appends all the elements from l2 to l1\n",
    "5. with open(file, 'r') as f: = Open the file as f in for the purposes of reading it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your TODO here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After writing your function, let's see the sentences we have created by running the code block below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 10 sentences\n",
      "------------------------\n",
      "1) enter king henry, lord john of lancaster, the earl of westmoreland, sir walter blunt, and others  so shaken as we are, so wan with care, find we a time for frighted peace to pant, and breathe short winded accents of new broils to be commenced in strands afar remote.\n",
      "2) no more the thirsty entrance of this soil shall daub her lips with her own children's blood; nor more shall trenching war channel her fields, nor bruise her flowerets with the armed hoofs of hostile paces: those opposed eyes, which, like the meteors of a troubled heaven, all of one nature, of one substance bred, did lately meet in the intestine shock and furious close of civil butchery shall now, in mutual well beseeming ranks, march all one way and be no more opposed against acquaintance, kindred and allies: the edge of war, like an ill sheathed knife, no more shall cut his master.\n",
      "3) therefore, friends, as far as to the sepulchre of christ, whose soldier now, under whose blessed cross we are impressed and engaged to fight, forthwith a power of english shall we levy; whose arms were moulded in their mothers' womb to chase these pagans in those holy fields over whose acres walk'd those blessed feet which fourteen hundred years ago were nail'd for our advantage on the bitter cross.\n",
      "4) but this our purpose now is twelve month old, and bootless 'tis to tell you we will go: therefore we meet not now.\n",
      "5) then let me hear of you, my gentle cousin westmoreland, what yesternight our council did decree in forwarding this dear expedience.\n",
      "6) my liege, this haste was hot in question, and many limits of the charge set down but yesternight: when all athwart there came a post from wales loaden with heavy news; whose worst was, that the noble mortimer, leading the men of herefordshire to fight against the irregular and wild glendower, was by the rude hands of that welshman taken, a thousand of his people butchered; upon whose dead corpse there was such misuse, such beastly shameless transformation, by those welshwomen done as may not be without much shame retold or spoken of.\n",
      "7) it seems then that the tidings of this broil brake off our business for the holy land.\n",
      "8) this match'd with other did, my gracious lord; for more uneven and unwelcome news came from the north and thus it did import: on holy rood day, the gallant hotspur there, young harry percy and brave archibald, that ever valiant and approved scot, at holmedon met, where they did spend a sad and bloody hour, as by discharge of their artillery, and shape of likelihood, the news was told; for he that brought them, in the very heat and pride of their contention did take horse, uncertain of the issue any way.\n",
      "9) here is a dear, a true industrious friend, sir walter blunt, new lighted from his horse.\n",
      "10) stain'd with the variation of each soil betwixt that holmedon and this seat of ours; and he hath brought us smooth and welcome news.\n"
     ]
    }
   ],
   "source": [
    "sentences = [s.strip() for s in sentences]\n",
    "print(f\"First {n} sentences\")\n",
    "print(\"------------------------\")\n",
    "for num, sent in enumerate(sentences[:n], 1):\n",
    "    print(f\"{num}) {sent}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Huzzah! We have our sentences. Now we shall build our markov chains using not one, but TWO different ways."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Act III: Lord Ihler's and His Matrix Servant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Professor Alexander Ihler is one of our advisors here for AI@UCI. He is currently teaching CS 179, which is a class about graphical models, where different variables express their dependencies to each other in the form of a graph. One graphical model that has been discussed are Markov chains (woah, we're doing a workshop on this). Like what we talked about earlier, we can represent our Markov chain with a transition matrix, which is a matrix of probabilities to get from one state to another. Let's see how we can use our knowledge to create one here. Once again, from scratch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all let's create a list of tokens. A token is a small unit of a piece of text and is essential in Natural Language Processing, a branch of AI. For our purposes, a token will be a word in the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_TODO_**: _Let us create a list of tokens based on the sentences list that we have created earlier._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Iterate through each sentence\n",
    "2. Remove any excess punctuation [',', ';', ':'] and replace them with a space\n",
    "3. Split the sentence into tokens (tokenization) and ensure that each token is lowercase\n",
    "4. Add those tokens into our token list (maintaining their order - this is very important)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hints**\n",
    "1. s.lower() -> str = Returns a lowercase version of the string s\n",
    "2. Previous hints given before can also help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your TODO here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_**Theory Review**_: _What will be the size of our transition matrix?_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hints**  \n",
    "1. np.unique(a) -> unique_elem, counts = Given an np.array, it returns an array of unique elements and their counts. Both are np.arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your answer here (show your work), your answer should be stored in a 2-tuple\n",
    "size = (0,0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you have a list of tokens, you can now create a transition matrix. So let's do that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_TODO_**: _Let us create a transition matrix to represent our Markov chain._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Initialize our matrix with a numpy matrix of zeros of size size (your theory answer comes in handy doesn't it)\n",
    "2. Initialize the first term (arrow) with the first word\n",
    "3. Populate the matrix while iterating through our token list\n",
    "4. Normalize the probabilities in each column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hints**\n",
    "1. np.zeros(size) -> np.array = Creates a matrix of size size filled with 0s\n",
    "2. l.index(e) -> x = Returns the index x of element e in the list l\n",
    "3. M[i,:] -> Row[i] = Gathers all the elements from row i\n",
    "4. M[:,j] -> Col[j] = Gathers all the elements from row j\n",
    "5. Operations on rows or columns will distribute to all elements in it (Ex. Row[i] += 1 will add one to every element in row i)\n",
    "6. sum(iterable) -> int/float = Sums up every element in an iterable (list, tuple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your TODO here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have our matrix, let's actually create an autocomplete and generate some text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_TODO_**: _Build an autocomplete or text generator using our transition matrix_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Initialize a start state (starting word) - Can be anything but if you dont have an idea, use \"thou\"\n",
    "2. Have a set length n (default 10 but can be anything you want), and in each iteration choose the next word based on your current word"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hints**\n",
    "1. np.random.choice(l, p=probs) -> e = Returns a random element e from a list l with weighted probabilities probs for each element.  \n",
    "_Note: len(l) == len(probs) and sum(probs) == 1_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = None\n",
    "chain = [start]\n",
    "# Write your TODO here\n",
    "generated_text = ' '.join(chain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now see the gifts of your work by running the code block below and have fun by rerunning the code block above. It's not going to generate the same string everytime (unless you set a seed)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(generated_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Act IV: King Yurichev, His Library of Dictionaries and N of His Grams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dennis Yurichev is a computer scientist who wrote \"Reverse Engineering for Beginners\". He wrote a blog post about creating a Markov chain autocomplete based on a given text. The theory of Markov chains is still present in this implementation. However, his approach is different from Ihler's as he uses dictionaries of dictionaries of counts rather than forming a transition matrix in order to generate words. We will look at his implementation as a review of the concepts used from the last act."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the code block below to setup and get started on the next act."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_stat(t, n=5):\n",
    "    total=float(sum(t.values()))\n",
    "    s=sorted(t.items(), key=lambda item: item[1], reverse=True)\n",
    "    for pair in s[:n]:\n",
    "        print (\"%s %d%%\" % (pair[0], (float(pair[1])/total)*100))\n",
    "\n",
    "def remove_empty_words(l):\n",
    "    return list(filter(lambda a: a != '', l))\n",
    "\n",
    "first=defaultdict(defaultdict(int)) # single word keys (Ex. \"to\")\n",
    "second=defaultdict(defaultdict(int)) # two word phrases as keys (Ex. \"to be\")\n",
    "third=defaultdict(defaultdict(int)) # three word phrases as keys (Ex. \"not to be\")\n",
    "\n",
    "# Sample example of what first could be\n",
    "# {\"to\": {\"be\": 1, \"meet\": 1}, \"or\": {\"not\": 1}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_TODO_**: _Let's update his dictionaries by filling our his update_occ function, and then populating the dictionary with connections and weights needed._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hints**\n",
    "1. Each dictionary (first, second, third) is in the form {phrase: {next_word: count}}\n",
    "2. Use the last 1, 2 or 3 words to create the phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* second order. for sequence: upon whose\n",
      "dead 10%\n",
      "side 10%\n",
      "influence 10%\n",
      "property 10%\n",
      "weal 10%\n",
      "* first order. for word: whose\n",
      "hand 1%\n",
      "high 1%\n",
      "tongue 0%\n",
      "name 0%\n",
      "father 0%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def update_occ(d, seq, w):\n",
    "    # Fill out TODO 1 here\n",
    "\n",
    "for s in sentences:\n",
    "    words = [] # TODO: \n",
    "    if len(words)==0:\n",
    "        continue\n",
    "    for i in range(len(words)):\n",
    "        # only two words available:\n",
    "        if i>=1:\n",
    "            continue #TODO: update the occurences -> {\"to\": {\"be\": 1}}\n",
    "        # three words available:\n",
    "        if i>=2:\n",
    "            continue #TODO: update the occurences -> {\"to be\": {\"or\": 1}}\n",
    "        # four words available:\n",
    "        if i>=3:\n",
    "            continue #TODO: update the occurences -> {\"not to be\": {\"that\": 1}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test your code by running the block below. You can change test to any phrase you would want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = \"it seems then\"\n",
    "test_words=test.split(\" \")\n",
    "\n",
    "test_len=len(test_words)\n",
    "last_idx=test_len-1\n",
    "\n",
    "if test_len>=3:\n",
    "    tmp=test_words[last_idx-2]+\" \"+test_words[last_idx-1]+\" \"+test_words[last_idx]\n",
    "    if tmp in third:\n",
    "        print (\"* third order. for sequence:\",tmp)\n",
    "        print_stat(third[tmp])\n",
    "\n",
    "if test_len>=2:\n",
    "    tmp=test_words[last_idx-1]+\" \"+test_words[last_idx]\n",
    "    if tmp in second:\n",
    "        print (\"* second order. for sequence:\", tmp)\n",
    "        print_stat(second[tmp])\n",
    "\n",
    "if test_len>=1:\n",
    "    tmp=test_words[last_idx]\n",
    "    if tmp in first:\n",
    "        print (\"* first order. for word:\", tmp)\n",
    "        print_stat(first[tmp])\n",
    "print (\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let us complete his autocomplete. It will be a similar process to what we have done before."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**_TODO_**: _Let's finish his selection function and use it to put recreate his autocomplete algorithm._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Finish the gen_random_from_tbl function\n",
    "2. Fill out the missing pieces of the for loop for text generation using gen_random_from_tbl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hints**\n",
    "1. random.choices(l, weights=w) -> e = Returns a random element e from a list l with weights/bias w  \n",
    "_Note: len(l) == len(w) but sum(w) not necessariliy equal to 1_\n",
    "2. Use the last 1, 2 or 3 words to create the phrase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "upon whose majesty in the sun and moon and clouded too fond of her love she's flown to her heaviness that's gone he shall go sleep with turks and infidels and in him he not deserve corn gratis the humourous man shall pass his word was 'hem boys might tend upon my scimitar's sharp point that it will not keep from whence came you in fine withdrew to mine own springe osric i am question'd by my name is douglas and sir thomas lovell take't of me now for this present summons unsolicited i left him there 'thus must thou needs be pitied much her sighs will make his friends blush that the white sheet and a many of his fines his double vouchers his recoveries to have them sleep on night but go after after cousin buckingham if ever thou heardest\n"
     ]
    }
   ],
   "source": [
    "text = ['upon', 'whose', 'majesty']\n",
    "\n",
    "def gen_random_from_tbl(t):\n",
    "    # TODO: Complete the function (Can you do it in one line?)\n",
    "    pass\n",
    "\n",
    "text_len=len(text)\n",
    "\n",
    "# generate at most 100 words:\n",
    "for i in range(200):\n",
    "    last_idx=text_len-1\n",
    "    tmp3= None #TODO: Create 3 word phrase using last_idx\n",
    "    tmp2= None #TODO: Create 2 word phrase using last_idx\n",
    "    tmp1= None #TODO: Create 1 word phrase using last_idx\n",
    "    if tmp3 in third:\n",
    "        new_word=None #TODO: Generate a new word\n",
    "    elif tmp2 in second:\n",
    "        new_word=None #TODO: Generate a new word\n",
    "    elif tmp1 in first:\n",
    "        new_word=None #TODO: Generate a new word\n",
    "    else:\n",
    "        break # dead end\n",
    "    text.append(new_word)\n",
    "    text_len=text_len+1\n",
    "\n",
    "print (\" \".join(text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Act V: Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you may have seen, although Ihler's and Yurichev's used different implementation, the basic idea of Markov chains are the same. Now in a discussion format all together, let's answer the following questions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. What are the similarities between Ihler's and Yurichev's implementations?\n",
    "2. What are the differences between Ihler's and Yurichev's implementations?\n",
    "3. Which implementation would you prefer and why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thank you for attending this workshop, and I hope you left this knowing something new."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exeunt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
